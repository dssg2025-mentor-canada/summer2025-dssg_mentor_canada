---
title: Linear reg, and XGBoost
subtitle: Week 4 (con'd) - 02
date: 2025-06-09
format: 
    html:
        toc: true
        embed-resources: true
        warning: false
        tbl-cap-location: bottom
---

# Linear model – Regression & Non-linear model – XGBoost

```{r}
#| output: false
#| warning: false
library(reticulate)
library(readr)
library(tidyr)
library(knitr)
library(arrow)
library(tidymodels)
library(regclass)
library(xgboost)
set.seed(512) # Set seed to ensure code result reproducibility for randomization
```

## Data Import

```{r}
ohe_unimputed_train <- read_feather('../../dssg-2025-mentor-canada/Data/ohe_unimputed_train.feather')
ohe_unimputed_train <- ohe_unimputed_train %>% mutate_all(~as.numeric(as.character(.)))


mean_mode_imputed_train <- read_feather("../../dssg-2025-mentor-canada/Data/mean_mode_imputed_train.feather")

# knn_imputed_train <- read_csv('../../dssg-2025-mentor-canada/Data/faiss_knn_imputed_dataset.csv')
knn_imputed_train <- read_csv('../../dssg-2025-mentor-canada/Data/faiss_tuned_knn_imputed_dataset.csv')

```

## Model fitting

### Linear model - Linear Regression (Ordinary Least Square Reg)

```{r}
#| echo: false
#| output: false
#| warning: false
mentor_ses_no_na_unimputed <- ohe_unimputed_train |>
                            select(QS1_28_EMPLOYMENT_calculated, QS3_4_LIFEEVENTS1_11_11_X1,QS3_4_LIFEEVENTS1_16_16_X1,
                                   QS3_4_LIFEEVENTS1_18_18_X1,QS2_3_PRESENCEOFM_Yes,QS2_9_PRESENCEOFA_Yes,
                                   QS2_6_MENTOREXPER, QS1_1_AGE) |>
                            na.omit()
subset <- ohe_unimputed_train |>
select(QS1_28_EMPLOYMENT_calculated, QS3_4_LIFEEVENTS1_11_11_X1,QS3_4_LIFEEVENTS1_16_16_X1,
                                   QS3_4_LIFEEVENTS1_18_18_X1,QS2_3_PRESENCEOFM_Yes,QS2_9_PRESENCEOFA_Yes,
                                   QS2_6_MENTOREXPER, QS1_1_AGE)
colSums(is.na(subset))

```

```{r}
#---unimputed
model <- lm(QS1_28_EMPLOYMENT_calculated ~  QS3_4_LIFEEVENTS1_11_11_X1 + 
                                            QS3_4_LIFEEVENTS1_16_16_X1 + 
                                            QS3_4_LIFEEVENTS1_18_18_X1 + 
                                            QS2_3_PRESENCEOFM_Yes +
                                            QS2_9_PRESENCEOFA_Yes + 
                                            QS1_1_AGE , 
            data = ohe_unimputed_train)
summary(model)
#----knn imputed
model_imputed <- lm(QS1_28_EMPLOYMENT_calculated ~  QS3_4_LIFEEVENTS1_11_11_X1 + 
                                            QS3_4_LIFEEVENTS1_16_16_X1 + 
                                            QS3_4_LIFEEVENTS1_18_18_X1 + 
                                            QS2_3_PRESENCEOFM_Yes +
                                            QS2_9_PRESENCEOFA_Yes + 
                                            QS1_1_AGE , 
            data = knn_imputed_train)
summary(model_imputed)

#----logistic unimputed
lg_model_unimputed <- glm(QS2_9_PRESENCEOFA_Yes ~  QS3_4_LIFEEVENTS1_11_11_X1 + 
                                         QS3_4_LIFEEVENTS1_16_16_X1 + 
                                         QS3_4_LIFEEVENTS1_18_18_X1 + 
                                         QS2_3_PRESENCEOFM_Yes + 
                                         QS1_1_AGE, 
            data = mean_mode_imputed_train,
            family = binomial)
summary(lg_model_unimputed)

#----logistic knn imputed
lg_model <- glm(QS2_9_PRESENCEOFA_Yes ~  QS3_4_LIFEEVENTS1_11_11_X1 + 
                                         QS3_4_LIFEEVENTS1_16_16_X1 + 
                                         QS3_4_LIFEEVENTS1_18_18_X1 + 
                                         QS2_3_PRESENCEOFM_Yes + 
                                         QS1_1_AGE, 
            data = knn_imputed_train,
            family = binomial)
summary(lg_model)
```

> -   Low R-squared suggests that the predictors, as specified, have limited practical/explanatory power for income.

### Running linear regression KNN imputed data:

```{r}
model_knn_imputed <- lm(QS1_28_EMPLOYMENT_calculated ~  QS3_4_LIFEEVENTS1_11_11_X1 + 
                                            QS3_4_LIFEEVENTS1_16_16_X1 + 
                                            QS3_4_LIFEEVENTS1_18_18_X1 + 
                                            QS2_3_PRESENCEOFM_Yes + 
                                            QS2_9_PRESENCEOFA_Yes + 
                                            QS2_6_MENTOREXPER + 
                                            QS1_1_AGE , 
            data = knn_imputed_train)
summary(model_knn_imputed)


lg_model_knn_imputed <- glm(QS2_9_PRESENCEOFA_Yes ~  QS3_4_LIFEEVENTS1_11_11_X1 + 
                                         QS3_4_LIFEEVENTS1_16_16_X1 + 
                                         QS3_4_LIFEEVENTS1_18_18_X1 + 
                                         QS2_3_PRESENCEOFM_Yes + 
                                         QS1_1_AGE, 
            data = knn_imputed_train,
            family = binomial)
summary(lg_model_knn_imputed)
```

#### Multicollinearity:

```{r}
VIF(model)
```

## Mentor Influence on Annual Income

```{r}
model_mentors_influence <- lm(QS1_28_EMPLOYMENT_calculated ~  QS2_36_INFLUENCE1_1_1 + 
                                                              QS2_36_INFLUENCE1_2_2 + 
                                                              QS2_36_INFLUENCE1_3_3 + 
                                                              QS2_36_INFLUENCE1_4_4 + 
                                                              QS2_36_INFLUENCE1_5_5 + 
                                                              QS2_36_INFLUENCE1_6_6 + 
                                                              QS2_36_INFLUENCE1_7_7 + 
                                                              QS2_36_INFLUENCE1_8_8 + 
                                                              QS2_36_INFLUENCE1_9_9 + QS1_1_AGE, 

                                data = mean_mode_imputed_train)
summary(model_mentors_influence)
```

```{r}
model_mentors_influence_knn_imputed <- lm(QS1_28_EMPLOYMENT_calculated ~  QS2_36_INFLUENCE1_1_1 + 
                                                              QS2_36_INFLUENCE1_2_2 + 
                                                              QS2_36_INFLUENCE1_3_3 + 
                                                              QS2_36_INFLUENCE1_4_4 + 
                                                              QS2_36_INFLUENCE1_5_5 + 
                                                              QS2_36_INFLUENCE1_6_6 + 
                                                              QS2_36_INFLUENCE1_7_7 + 
                                                              QS2_36_INFLUENCE1_8_8 + 
                                                              QS2_36_INFLUENCE1_9_9 + QS1_1_AGE, 

                                data = knn_imputed_train)
summary(model_mentors_influence_knn_imputed)
```

## Model specification (Lasso regression with L1 regularization with `mixture = 1`)

(Workflow with tidymodels–for now has echo: false)

```{r}
#| echo: false
# ridge_spec <- linear_reg(penalty = tune(), mixture = 0) |> 
# set_mode("regression") |> 
# set_engine("glmnet")
```

```{r}
#| echo: false

# fit <- linear_reg(penalty = 1) |>
#         set_engine("glmnet") |>
#         fit(QS1_28_EMPLOYMENT_calculated ~ ., data = mean_mode_imputed_train)

# lm_wkflw <- workflow() |>
#         add_recipe(recipe_to_fit) |>
#         add_model(lm_spec)
#         fit(lm_wkflw, data = mean_mode_imputed_train)
```

#### Define cross-validation (CV) folds for tuning & grid:

```{r}
#| echo: false

# cv_folds <- vfold_cv(imputed_train_fit, v = 10)
# grid <- grid_regular(penalty(range = c(-3, 3)), levels = 20)
```

### `Tidymodels` Workflow

```{r}
#| echo: false

#ridge_wkflw <- workflow() |>       
#add_recipe(recipe_to_fit) |>     
#add_model(ridge_spec)
```

### Tuning Regularization Penalty

```{r}
#| echo: false

# ridge_tune <- tune_grid(ridge_wkflw, resamples = cv_folds, grid = grid, metrics = metric_set(rmse))
```

```{r}
#| echo: false

# Fit Ridge model (alpha = 0)
# View model summary

```

```{r}
#| echo: false

  # Perform cross-validation to select optimal lambda
# x_train <- select(mean_mode_imputed_train, -QS1_28_EMPLOYMENT_calculated)
# y_train <- select(mean_mode_imputed_train, QS1_28_EMPLOYMENT_calculated)

# # Optimal lambda
# best_lambda <- cv_ridge$lambda.min

# # Plot cross-validation results
# plot(cv_ridge)
```

```{r}
#| echo: false

#   ses_youth <- select(youth, QS3_4_LIFEEVENTS1_11_11, QS3_4_LIFEEVENTS1_16_16, QS3_4_LIFEEVENTS1_18_18, QS1_28_EMPLOYMENT_calculated)
# rec <- recipe(QS1_28_EMPLOYMENT_calculated~QS3_4_LIFEEVENTS1_11_11 + QS3_4_LIFEEVENTS1_16_16 + QS3_4_LIFEEVENTS1_18_18, data = ses_youth)
# dummies_recipe <- rec |> step_dummy(all_predictors(), one_hot = TRUE)
# dummies_data <- dummies_recipe |> prep() |> bake(new_data = NULL)
# dummies_data
```

## XGB

### XGB model 1:

#### All 3 SES indicators, mentor experiences, age, and year of higher education completion.

**(Mean mode imputed)**:

```{r}
#| output: false
x <- model.matrix(~ QS3_4_LIFEEVENTS1_16_16_X1 + QS2_3_PRESENCEOFM_Yes + 
                  QS2_9_PRESENCEOFA_Yes + QS2_6_MENTOREXPER + 
                  QS1_1_AGE + QS1_23_YEARCOMPLE, 
                  data = mean_mode_imputed_train)[, -1]
y <- log(mean_mode_imputed_train$QS1_28_EMPLOYMENT_calculated + 1)
dmatrix <- xgb.DMatrix(x, label = y)
xgb_model <- xgboost(data = dmatrix, nrounds = 100, objective = "reg:squarederror", 
                     params = list(max_depth = 4, eta = 0.1))
xgb.importance(model = xgb_model)

xgb.plot.importance(xgb.importance(model = xgb_model))

```

```{r}
#| output: false
xgb_importance_df <- xgb.importance(model = xgb_model)

xgb_cv <- xgb.cv(params = list(max_depth = 4, eta = 0.1), data = dmatrix, nrounds = 200, nfold = 5)
```

```{r}
xgb.plot.importance(xgb.importance(model = xgb_model))
kable(xgb_importance_df)
```

**(KNN imputed)**:

```{r}
#| output: false
x_knn_imputed <- model.matrix(~ QS3_4_LIFEEVENTS1_16_16_X1 + QS2_3_PRESENCEOFM_Yes + 
                  QS2_9_PRESENCEOFA_Yes + QS2_6_MENTOREXPER + 
                  QS1_1_AGE + QS1_23_YEARCOMPLE, 
                  data = knn_imputed_train)[, -1]
y_knn_imputed <- log(knn_imputed_train$QS1_28_EMPLOYMENT_calculated + 1)
dmatrix_knn_imputed <- xgb.DMatrix(x_knn_imputed, label = y_knn_imputed)
xgb_model_knn_imputed <- xgboost(data = dmatrix_knn_imputed, nrounds = 100, objective = "reg:squarederror", 
                     params = list(max_depth = 4, eta = 0.1))
xgb.importance(model = xgb_model_knn_imputed)

xgb.plot.importance(xgb.importance(model = xgb_model_knn_imputed))

```

```{r}
#| output: false
xgb_importance_knn_imputed_df <- xgb.importance(model = xgb_model_knn_imputed)

xgb_cv_knn_imputed <- xgb.cv(params = list(max_depth = 4, eta = 0.1), data = dmatrix, nrounds = 200, nfold = 5)
```

```{r}
xgb.plot.importance(xgb.importance(model = xgb_model_knn_imputed))
kable(xgb_importance_knn_imputed_df)
```

### XGB model 2:

#### All 3 SES indicators, mentor experiences, and age.

```{r}
#| output: false
x <- model.matrix(~ QS3_4_LIFEEVENTS1_11_11_X1 + QS3_4_LIFEEVENTS1_16_16_X1 +  QS3_4_LIFEEVENTS1_18_18_X1 + QS2_3_PRESENCEOFM_Yes + QS2_9_PRESENCEOFA_Yes + QS2_6_MENTOREXPER + QS1_1_AGE, data = mean_mode_imputed_train)[, -1]

y <- log(mean_mode_imputed_train$QS1_28_EMPLOYMENT_calculated + 1)
dmatrix <- xgb.DMatrix(x, label = y)
xgb_model <- xgboost(data = dmatrix, nrounds = 100, objective = "reg:squarederror", 
params = list(max_depth = 4, eta = 0.1))

xgb_importance_df <- xgb.importance(model = xgb_model)

xgb_cv <- xgb.cv(params = list(max_depth = 4, eta = 0.1), data = dmatrix, nrounds = 200, nfold = 5)
```

```{r}
xgb.plot.importance(xgb.importance(model = xgb_model))
write_csv(xgb_importance_df, "outputs/tables/week-04/02-xgb-importance.csv")
kable(xgb_importance_df)
```

**(KNN imputed)**:

```{r}
#| output: false
x_knn_imputed <- model.matrix(~ QS3_4_LIFEEVENTS1_11_11_X1 + QS3_4_LIFEEVENTS1_16_16_X1 +  QS3_4_LIFEEVENTS1_18_18_X1 + QS2_3_PRESENCEOFM_Yes + QS2_9_PRESENCEOFA_Yes + QS2_6_MENTOREXPER + QS1_1_AGE, 
                  data = knn_imputed_train)[, -1]
y_knn_imputed <- log(knn_imputed_train$QS1_28_EMPLOYMENT_calculated + 1)
dmatrix_knn_imputed <- xgb.DMatrix(x_knn_imputed, label = y_knn_imputed)
xgb_model_knn_imputed <- xgboost(data = dmatrix_knn_imputed, nrounds = 100, objective = "reg:squarederror", 
                     params = list(max_depth = 4, eta = 0.1))
xgb.importance(model = xgb_model_knn_imputed)

xgb.plot.importance(xgb.importance(model = xgb_model_knn_imputed))

```

```{r}
#| output: false
xgb_importance_knn_imputed_df <- xgb.importance(model = xgb_model_knn_imputed)

xgb_cv_knn_imputed <- xgb.cv(params = list(max_depth = 4, eta = 0.1), data = dmatrix, nrounds = 200, nfold = 5)
```

```{r}
xgb.plot.importance(xgb.importance(model = xgb_model_knn_imputed))
kable(xgb_importance_knn_imputed_df)
```